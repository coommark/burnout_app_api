{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "80d4f9b2-bb79-446e-99a1-21167123d49e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Logistic Regression ===\n",
      "Calibration:\n",
      "  Brier (OVR) per class: {'High': '0.0029', 'Low': '0.0021', 'Moderate': '0.0052'}\n",
      "  Brier (multiclass): 0.0102\n",
      "  Log loss: 0.0376\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        High       1.00      0.98      0.99        60\n",
      "         Low       1.00      1.00      1.00       150\n",
      "    Moderate       0.99      1.00      0.99        90\n",
      "\n",
      "    accuracy                           1.00       300\n",
      "   macro avg       1.00      0.99      1.00       300\n",
      "weighted avg       1.00      1.00      1.00       300\n",
      "\n",
      "ROC-AUC (macro, OVR): 1.000\n",
      "\n",
      "Confusion Matrix:\n",
      "          High  Low  Moderate\n",
      "High        59    0         1\n",
      "Low          0  150         0\n",
      "Moderate     0    0        90\n",
      "\n",
      "=== Random Forest ===\n",
      "Calibration:\n",
      "  Brier (OVR) per class: {'High': '0.0006', 'Low': '0.0006', 'Moderate': '0.0012'}\n",
      "  Brier (multiclass): 0.0023\n",
      "  Log loss: 0.0083\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        High       1.00      1.00      1.00        60\n",
      "         Low       1.00      1.00      1.00       150\n",
      "    Moderate       1.00      1.00      1.00        90\n",
      "\n",
      "    accuracy                           1.00       300\n",
      "   macro avg       1.00      1.00      1.00       300\n",
      "weighted avg       1.00      1.00      1.00       300\n",
      "\n",
      "ROC-AUC (macro, OVR): 1.000\n",
      "\n",
      "Confusion Matrix:\n",
      "          High  Low  Moderate\n",
      "High        60    0         0\n",
      "Low          0  150         0\n",
      "Moderate     0    0        90\n",
      "\n",
      "=== XGBoost ===\n",
      "Calibration:\n",
      "  Brier (OVR) per class: {'High': '0.0009', 'Low': '0.0001', 'Moderate': '0.0009'}\n",
      "  Brier (multiclass): 0.0019\n",
      "  Log loss: 0.0053\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        High       1.00      0.98      0.99        60\n",
      "         Low       1.00      1.00      1.00       150\n",
      "    Moderate       0.99      1.00      0.99        90\n",
      "\n",
      "    accuracy                           1.00       300\n",
      "   macro avg       1.00      0.99      1.00       300\n",
      "weighted avg       1.00      1.00      1.00       300\n",
      "\n",
      "ROC-AUC (macro, OVR): 1.000\n",
      "\n",
      "Confusion Matrix:\n",
      "          High  Low  Moderate\n",
      "High        59    0         1\n",
      "Low          0  150         0\n",
      "Moderate     0    0        90\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import (\n",
    "    classification_report, confusion_matrix, roc_auc_score,\n",
    "    brier_score_loss, log_loss\n",
    ")\n",
    "from sklearn.calibration import calibration_curve\n",
    "from sklearn.preprocessing import label_binarize\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import joblib\n",
    "import os\n",
    "\n",
    "# ----------------------------------\n",
    "# Helper functions (define first!)\n",
    "# ----------------------------------\n",
    "def multiclass_brier_score(y_true_int, y_proba, classes):\n",
    "    \"\"\"\n",
    "    Generalized Brier score for multi-class: mean over samples of sum_j (p_ij - y_ij)^2\n",
    "    \"\"\"\n",
    "    Y = label_binarize(y_true_int, classes=classes)  # shape: (n_samples, n_classes)\n",
    "    return float(np.mean(np.sum((y_proba - Y) ** 2, axis=1)))\n",
    "\n",
    "def plot_reliability_curves(y_true_int, y_proba, class_names, model_name, safe_name, outdir=\"./output\"):\n",
    "    \"\"\"\n",
    "    One-vs-rest reliability (calibration) curves for each class (per-model figure).\n",
    "    \"\"\"\n",
    "    classes = np.arange(len(class_names))\n",
    "    fig, axes = plt.subplots(1, len(class_names), figsize=(5 * len(class_names), 4), sharey=True)\n",
    "    if len(class_names) == 1:\n",
    "        axes = [axes]\n",
    "\n",
    "    for k, cls_name in enumerate(class_names):\n",
    "        y_true_bin = (y_true_int == classes[k]).astype(int)\n",
    "        frac_pos, mean_pred = calibration_curve(y_true_bin, y_proba[:, k], n_bins=10, strategy=\"quantile\")\n",
    "\n",
    "        ax = axes[k]\n",
    "        ax.plot(mean_pred, frac_pos, marker=\"o\")\n",
    "        ax.plot([0, 1], [0, 1], linestyle=\"--\", linewidth=1)\n",
    "        ax.set_title(f\"{model_name}: {cls_name}\")\n",
    "        ax.set_xlabel(\"Mean predicted probability\")\n",
    "        if k == 0:\n",
    "            ax.set_ylabel(\"Fraction of positives\")\n",
    "        ax.set_xlim(0, 1)\n",
    "        ax.set_ylim(0, 1)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    os.makedirs(outdir, exist_ok=True)\n",
    "    plt.savefig(f\"{outdir}/{safe_name}_reliability.png\", dpi=200)\n",
    "    plt.close()\n",
    "\n",
    "def plot_reliability_combined(results, class_names, outpath=\"./output/reliability_combined.png\"):\n",
    "    \"\"\"\n",
    "    Combined reliability figure: 1 row x (#models) columns.\n",
    "    Each panel shows three class curves for the corresponding model.\n",
    "    \"\"\"\n",
    "    n_models = len(results)\n",
    "    fig, axes = plt.subplots(1, n_models, figsize=(5 * n_models, 4), sharey=True)\n",
    "    if n_models == 1:\n",
    "        axes = [axes]\n",
    "\n",
    "    for ax, res in zip(axes, results):\n",
    "        y_true_int = res[\"y_true_int\"]\n",
    "        y_proba = res[\"y_proba\"]\n",
    "        model_name = res[\"name\"]\n",
    "\n",
    "        classes = np.arange(len(class_names))\n",
    "        for k, cls_name in enumerate(class_names):\n",
    "            y_true_bin = (y_true_int == classes[k]).astype(int)\n",
    "            frac_pos, mean_pred = calibration_curve(y_true_bin, y_proba[:, k], n_bins=10, strategy=\"quantile\")\n",
    "            ax.plot(mean_pred, frac_pos, marker=\"o\", label=cls_name)\n",
    "\n",
    "        ax.plot([0, 1], [0, 1], linestyle=\"--\", linewidth=1)\n",
    "        ax.set_title(model_name)\n",
    "        ax.set_xlabel(\"Mean predicted probability\")\n",
    "        ax.set_xlim(0, 1)\n",
    "        ax.set_ylim(0, 1)\n",
    "\n",
    "    axes[0].set_ylabel(\"Fraction of positives\")\n",
    "    axes[-1].legend(title=\"Class\", loc=\"lower right\")\n",
    "    plt.tight_layout()\n",
    "    os.makedirs(os.path.dirname(outpath), exist_ok=True)\n",
    "    plt.savefig(outpath, dpi=200)\n",
    "    plt.close()\n",
    "\n",
    "def plot_confusion_matrices_combined(results, class_names, outpath=\"./output/confusion_matrices_combined.png\"):\n",
    "    \"\"\"\n",
    "    Combined confusion-matrix figure: 1 row x (#models) columns.\n",
    "    \"\"\"\n",
    "    n_models = len(results)\n",
    "    fig, axes = plt.subplots(1, n_models, figsize=(5 * n_models, 4), sharey=True)\n",
    "    if n_models == 1:\n",
    "        axes = [axes]\n",
    "\n",
    "    for ax, res in zip(axes, results):\n",
    "        cm = res[\"cm\"]\n",
    "        model_name = res[\"name\"]\n",
    "        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "                    xticklabels=class_names, yticklabels=class_names, ax=ax)\n",
    "        ax.set_title(f\"{model_name}\")\n",
    "        ax.set_xlabel(\"Predicted\")\n",
    "        ax.set_ylabel(\"Actual\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    os.makedirs(os.path.dirname(outpath), exist_ok=True)\n",
    "    plt.savefig(outpath, dpi=200)\n",
    "    plt.close()\n",
    "\n",
    "def print_reliability_tables(y_true_int, y_proba, class_names, n_bins=10):\n",
    "    \"\"\"\n",
    "    Print quantile-binned reliability (calibration) tables per class:\n",
    "    columns: bin, mean_pred (avg predicted prob), frac_pos (observed rate)\n",
    "    \"\"\"\n",
    "    classes = np.arange(len(class_names))\n",
    "    for k, cls_name in enumerate(class_names):\n",
    "        y_true_bin = (y_true_int == classes[k]).astype(int)\n",
    "        frac_pos, mean_pred = calibration_curve(\n",
    "            y_true_bin, y_proba[:, k], n_bins=n_bins, strategy=\"quantile\"\n",
    "        )\n",
    "        calib_df = pd.DataFrame({\n",
    "            \"bin\": np.arange(1, len(frac_pos) + 1),\n",
    "            \"mean_pred\": np.round(mean_pred, 3),\n",
    "            \"frac_pos\": np.round(frac_pos, 3)\n",
    "        })\n",
    "        print(f\"\\nReliability (quantile bins) — Class: {cls_name}\")\n",
    "        print(calib_df.to_string(index=False))\n",
    "\n",
    "# ----------------------------------\n",
    "# Main\n",
    "# ----------------------------------\n",
    "os.makedirs(\"./output\", exist_ok=True)\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(\"./data/simulated_weekly_burnout.csv\")\n",
    "\n",
    "# Encode categorical target\n",
    "label_encoder = LabelEncoder()\n",
    "df[\"burnout_label\"] = label_encoder.fit_transform(df[\"burnout\"])\n",
    "\n",
    "# Define features\n",
    "features = ['avg_tired', 'avg_capable', 'avg_meaningful']\n",
    "X = df[features]\n",
    "y = df[\"burnout_label\"]\n",
    "\n",
    "# Train/test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, stratify=y, test_size=0.3, random_state=42\n",
    ")\n",
    "\n",
    "# Scale features (only for Logistic Regression)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Initialize models\n",
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(\n",
    "        multi_class='multinomial', solver='lbfgs', max_iter=1000, random_state=42\n",
    "    ),\n",
    "    \"Random Forest\": RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "    \"XGBoost\": XGBClassifier(\n",
    "        objective='multi:softprob', num_class=3, eval_metric='mlogloss',\n",
    "        random_state=42\n",
    "    )\n",
    "}\n",
    "\n",
    "# Collect results for combined figures\n",
    "combined_results = []\n",
    "\n",
    "# Train, evaluate, and save each model\n",
    "for name, model in models.items():\n",
    "    print(f\"\\n=== {name} ===\")\n",
    "    safe_name = name.lower().replace(\" \", \"_\")  # make available early\n",
    "\n",
    "    # Fit\n",
    "    if name == \"Logistic Regression\":\n",
    "        model.fit(X_train_scaled, y_train)\n",
    "        X_eval = X_test_scaled\n",
    "    else:\n",
    "        model.fit(X_train, y_train)\n",
    "        X_eval = X_test\n",
    "\n",
    "    # Predict labels and probabilities\n",
    "    y_pred = model.predict(X_eval)\n",
    "    y_proba = model.predict_proba(X_eval)\n",
    "\n",
    "    # ---------- Calibration metrics ----------\n",
    "    n_classes = len(label_encoder.classes_)\n",
    "    classes_idx = np.arange(n_classes)\n",
    "    Y_bin = label_binarize(y_test, classes=classes_idx)\n",
    "\n",
    "    # (a) One-vs-rest Brier score per class\n",
    "    brier_per_class = {}\n",
    "    for k, cls in enumerate(label_encoder.classes_):\n",
    "        brier_k = brier_score_loss(Y_bin[:, k], y_proba[:, k])\n",
    "        brier_per_class[cls] = brier_k\n",
    "\n",
    "    # (b) Multiclass Brier score (generalized)\n",
    "    brier_multi = multiclass_brier_score(y_test, y_proba, classes_idx)\n",
    "\n",
    "    # (c) Log loss (cross-entropy)\n",
    "    ll = log_loss(y_test, y_proba, labels=classes_idx)\n",
    "\n",
    "    print(\"Calibration:\")\n",
    "    print(\"  Brier (OVR) per class:\", {k: f\"{v:.4f}\" for k, v in brier_per_class.items()})\n",
    "    print(f\"  Brier (multiclass): {brier_multi:.4f}\")\n",
    "    print(f\"  Log loss: {ll:.4f}\")\n",
    "\n",
    "    # Print reliability (calibration) tables per class\n",
    "    print_reliability_tables(y_true_int=y_test, y_proba=y_proba, class_names=label_encoder.classes_, n_bins=10)\n",
    "\n",
    "    # (d) Reliability (calibration) curves (per-model; saved to ./output)\n",
    "    plot_reliability_curves(\n",
    "        y_true_int=y_test,\n",
    "        y_proba=y_proba,\n",
    "        class_names=label_encoder.classes_,\n",
    "        model_name=name,\n",
    "        safe_name=safe_name,\n",
    "        outdir=\"./output\"\n",
    "    )\n",
    "\n",
    "    # ---------- Interpretability summaries ----------\n",
    "    # Logistic Regression: coefficients & odds ratios\n",
    "    if name == \"Logistic Regression\":\n",
    "        coefs_df = pd.DataFrame(model.coef_, columns=features, index=label_encoder.classes_)\n",
    "        odds_df = np.exp(coefs_df)\n",
    "        coefs_df.to_csv(f\"./output/{safe_name}_coefficients.csv\")\n",
    "        odds_df.to_csv(f\"./output/{safe_name}_odds_ratios.csv\")\n",
    "\n",
    "        plt.figure(figsize=(6, 3.5))\n",
    "        sns.heatmap(coefs_df, annot=True, fmt=\".2f\", cmap=\"coolwarm\", center=0)\n",
    "        plt.title(\"Multinomial Logistic Regression Coefficients\")\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f\"./output/{safe_name}_coef_heatmap.png\", dpi=200)\n",
    "        plt.close()\n",
    "\n",
    "        # Console summaries (rounded) for quick reading\n",
    "        print(\"\\nLogistic Regression — Coefficients (per class):\")\n",
    "        print(coefs_df.round(3).to_string())\n",
    "\n",
    "        print(\"\\nLogistic Regression — Odds ratios (per class):\")\n",
    "        print(odds_df.round(3).to_string())\n",
    "\n",
    "        # Optional: quick “top driver” per class by absolute coefficient\n",
    "        abs_coefs = coefs_df.abs()\n",
    "        top_drivers = abs_coefs.idxmax(axis=1)\n",
    "        print(\"\\nTop driver feature per class (by |coef|):\")\n",
    "        for cls in coefs_df.index:\n",
    "            feat = top_drivers.loc[cls]\n",
    "            sign = \"↑ (risk up)\" if coefs_df.loc[cls, feat] > 0 else \"↓ (risk down)\"\n",
    "            print(f\"  {cls}: {feat} ({coefs_df.loc[cls, feat]:.3f}) {sign}\")\n",
    "\n",
    "    # Tree models: native feature importances\n",
    "    if hasattr(model, \"feature_importances_\"):\n",
    "        imp = pd.Series(model.feature_importances_, index=features).sort_values(ascending=False)\n",
    "        imp.to_csv(f\"./output/{safe_name}_feature_importances.csv\")\n",
    "\n",
    "        plt.figure(figsize=(5, 3.5))\n",
    "        imp.plot(kind=\"bar\")\n",
    "        plt.ylabel(\"Importance\")\n",
    "        plt.title(f\"{name} Feature Importances\")\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f\"./output/{safe_name}_feature_importances.png\", dpi=200)\n",
    "        plt.close()\n",
    "\n",
    "        print(f\"\\n{name} — Feature importances:\")\n",
    "        print(imp.round(3).to_string())\n",
    "        # Optional: one-line driver summary\n",
    "        top_feat = imp.index[0]\n",
    "        print(f\"Top driver: {top_feat} ({imp.iloc[0]:.3f})\")\n",
    "\n",
    "    # Decode labels for display\n",
    "    y_test_labels = label_encoder.inverse_transform(y_test)\n",
    "    y_pred_labels = label_encoder.inverse_transform(y_pred)\n",
    "\n",
    "    # 1) Classification Report\n",
    "    print(\"Classification Report:\")\n",
    "    print(classification_report(y_test_labels, y_pred_labels))\n",
    "\n",
    "    # 2) ROC-AUC (macro-averaged One-vs-Rest)\n",
    "    roc_auc = roc_auc_score(\n",
    "        y_true=y_test,\n",
    "        y_score=y_proba,\n",
    "        multi_class='ovr',\n",
    "        average='macro'\n",
    "    )\n",
    "    print(f\"ROC-AUC (macro, OVR): {roc_auc:.3f}\\n\")\n",
    "\n",
    "    # 3) Confusion Matrix\n",
    "    cm = confusion_matrix(\n",
    "        y_test_labels, y_pred_labels, labels=label_encoder.classes_\n",
    "    )\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(pd.DataFrame(cm, index=label_encoder.classes_, columns=label_encoder.classes_))\n",
    "\n",
    "    # Plot heatmap AND SAVE IMAGE (per-model)\n",
    "    plt.figure(figsize=(5, 4))\n",
    "    sns.heatmap(\n",
    "        cm, annot=True, fmt='d', cmap='Blues',\n",
    "        xticklabels=label_encoder.classes_,\n",
    "        yticklabels=label_encoder.classes_\n",
    "    )\n",
    "    plt.title(f\"{name} Confusion Matrix\")\n",
    "    plt.xlabel(\"Predicted\")\n",
    "    plt.ylabel(\"Actual\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"./output/{safe_name}_confusion_matrix.png\", dpi=200)\n",
    "    plt.close()\n",
    "\n",
    "    # Save the model\n",
    "    joblib.dump(model, f\"./output/{safe_name}_model.pkl\")\n",
    "\n",
    "    # ---- Collect for combined figures ----\n",
    "    combined_results.append({\n",
    "        \"name\": name,\n",
    "        \"safe_name\": safe_name,\n",
    "        \"y_true_int\": y_test,\n",
    "        \"y_proba\": y_proba,\n",
    "        \"cm\": cm\n",
    "    })\n",
    "\n",
    "# Save preprocessing tools\n",
    "joblib.dump(scaler, \"./output/burnout_scaler.pkl\")\n",
    "joblib.dump(label_encoder, \"./output/burnout_label_encoder.pkl\")\n",
    "\n",
    "# ---------- Create combined figures ----------\n",
    "plot_reliability_combined(\n",
    "    results=combined_results,\n",
    "    class_names=label_encoder.classes_,\n",
    "    outpath=\"./output/reliability_combined.png\"\n",
    ")\n",
    "\n",
    "plot_confusion_matrices_combined(\n",
    "    results=combined_results,\n",
    "    class_names=label_encoder.classes_,\n",
    "    outpath=\"./output/confusion_matrices_combined.png\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8c784fd-3184-4457-bc73-b5c42c19e1e7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
